---
title: "Race Predictors..  "
subtitle: "Art vs Science"
date: 04/09/2025
categories: [Running, Data Science, GCM25]
date-modified: last-modified
format:
  html:
    code-fold: true
    toc: false
draft: false
bibliography: references.bib
---

> “All models are wrong, but some are useful.”[^1] — George Box

[^1]: quote generally attributed to [George E. P. Box](https://en.wikipedia.org/wiki/George_E._P._Box), a British statistician, who argued models are never perfect by may still be useful in everyday life

Before diving into the training data, let’s take a quick detour into the curious, and sometimes overly optimistic, world of race prediction models. Most runners have come across these at some point: you plug in a recent race result, hit "calculate," and voilà — a predicted marathon time appears!

The Riegel equation[^2], or some variation of it, is perhaps the most well-known. It uses a race result over a known distance to estimate a predicted finish time for another distance, based on an exponential decay formula.

[^2]: proposed by [Peter Riegel](https://en.wikipedia.org/wiki/Peter_Riegel) in a Runner's World article in 1977

Specifically, the formula is:

$$
T_2 = T_1 \times \left( \frac{D_2}{D_1} \right)^b
$$ Where:

**T₁** = time over distance D₁

**T₂** = predicted time over distance D₂

**b** = decay exponent - originally proposed by Riegel to be 1.06

Some more sober-minded folks argue the exponent should be higher—closer to 1.15—and you can read more about the logic behind that in the linked article - see: [FetchEveryone's improved Riegel calculator](https://www.fetcheveryone.com/training-calculators-improvedriegel.php?hours=1&minutes=24&seconds=0) . Running watches also provide predictors. Mine, a Garmin, currently pegs my marathon fitness at 3:11:xx. Where it gets this number from is anyone’s guess. Presumably a mix of VO₂ max estimates, and recent efforts.

But there are other prediction methods that draw on your training data rather than race results. After sharing my [past marathon times](https://edwchris.github.io/blog/posts/TheBeginningStagesof/) in a previous post, I started wondering how well the training leading into those races actually correlated with my finish times.

**Enter Tanda.**

Developed by Giovanni Tanda from the University of Genova, this model is based on actual training data, not race times. His 2011 paper[@tanda2011] looked at a bunch of training logs and used regression analysis to see what best predicted marathon pace (and by extension marathon finish time).

The result? For the 8 weeks leading into the final week of training, the paper excluded the final taper week, the two key variables that correlated best with finish times were:

• K = average weekly distance (km/week)

• P = average training pace (sec/km)

There are, of course, some obvious limitations to the study. It included a modest number of runners (and only one female), and it didn’t attempt to correlate performance with things like individual VO₂ max, lactate threshold, body composition, or biomechanics—factors that are known to influence performance.

Christof Schwiening has written a [brilliant blog](https://christofschwiening.blogspot.com/) exploring the Tanda model in depth, for those keen to venture further down the rabbit hole. One of his best analogies compares Tanda nicely to other race predictors:

> “...the Tanda 8-week period is just another race. It is the training race – a race with no defined distance or time, but a race nevertheless.”[^3]

[^3]: Understanding race predictors - Riegel versus Tanda - Christof Schwiening [blog](https://christofschwiening.blogspot.com/2019/05/understanding-race-predictors-riegel.html)

For me, it was just an interesting exercise to see how the model held up. So I went full archaeologist on the 8 weeks leading into all 12 previous marathons. I dug up the P and the K, and ran the Tanda model for each.

Below is the output

```{r}
#| warning: false
#| include: false
library(tidyverse)
library(gt)
library(readxl)

# Read the Excel file
tanda_data <- read_excel("data/tanda.xlsx")
```

```{r}
tanda_data %>%
  select(Race, Avg_Dist_week_K,
         Predicted_Time, Pace, Time, Difference, Over_Under_Tanda) %>%
  gt() %>%
  tab_header(
    title = "Marathon Performance vs Tanda Prediction"
  ) %>%
  tab_spanner(
    label = "Training Summary",
    columns = c(Avg_Dist_week_K, Pace)
  ) %>%
  tab_spanner(
    label = "Race Performance",
    columns = c(Predicted_Time, Time, Difference, Over_Under_Tanda)
  ) %>%
  cols_label(
    Race = "Event",
    Avg_Dist_week_K = "Avg Weekly Distance (K, km)",
    Pace = "Training Pace (P, sec/km)",
    Predicted_Time = "Tanda Prediction (hh:mm:ss)",
    Time = "Actual Time (hh:mm:ss)",
    Difference = "Difference (mm:ss)",
    Over_Under_Tanda = "Over/Under"
  ) %>%
  fmt_number(
    columns = Avg_Dist_week_K,
    decimals = 1
  ) %>%
  fmt_number(
    columns = Pace,
    decimals = 0
  ) %>%
  tab_source_note(
    source_note = md(
      "Tanda equation: $Pm (sec/km) = 17.1 + 140.0 \\cdot \\exp(-0.0053 \\cdot K) + 0.55 \\cdot P$"
    )
  )



```

I’m not entirely sure how to interpret this. Based on the Tanda predictions, I outperformed the model in half of my races and underperformed in the other half. In other words, it was a coin toss.

The Bland–Altman plot[^5] below doesn’t offer much insight either. There’s no meaningful bias between the Tanda prediction and my actual marathon finish times the [blue line]{style="color:blue;"} howers around 0 on the *y-axis*. Which I suppose is a good thing.

[^5]: Wikipedia reference for the [Bland- Altman plot](https://en.wikipedia.org/wiki/Bland%E2%80%93Altman_plot)

What's more concerning is the width of the Limits of Agreement (LoA). The [red-dotted lines]{style="color:red;"} hovers around *±25 minutes* — which is wild. That essentially means there's 95% "confidence" that my actual time could be anywhere within 25 minutes of the Tanda prediction for any given race build-up. Not exactly razor-sharp guidance.

Also, I have a feeling the finishes over 3:30 are skewing the results. Two of those were significant blow-ups — races where things really unravelled in the later stages. The third was more of a social run, where I paced comfortably alongside a mate.

All up, it’s a reminder that while models like Tanda can offer a rough guide, they don’t always capture the messiness of the marathon. And maybe that’s the point: running isn’t always about prediction — sometimes it’s about embracing the unknown, the artistry of pacing, the conditions on the day, and that delicate mix of patience and bravery that makes each race its own adventure.

```{r}


library(tidyverse)
library(lubridate)

# Prepare the data using base conversions
tanda_ba <- tanda_data %>%
  mutate(
    Pred_sec = as.numeric(lubridate::period_to_seconds(lubridate::hms(Predicted_Time))),
    Time_sec = as.numeric(lubridate::period_to_seconds(lubridate::hms(Time))),
    Mean_time = (Pred_sec + Time_sec) / 2,
    Diff_time = Time_sec - Pred_sec
  )

# Compute bias and limits of agreement
bias <- mean(tanda_ba$Diff_time, na.rm = TRUE)
sd_diff <- sd(tanda_ba$Diff_time, na.rm = TRUE)
loa_upper <- bias + 1.96 * sd_diff
loa_lower <- bias - 1.96 * sd_diff

# Custom formatter for x-axis (hh:mm)
sec_to_hhmm <- function(x) {
  hours <- floor(x / 3600)
  minutes <- floor((x %% 3600) / 60)
  sprintf("%02d:%02d", hours, minutes)
}

# Create Bland–Altman plot
BA_plot<- ggplot(tanda_ba, aes(x = Mean_time, y = Diff_time)) +
  geom_point() +
  geom_hline(yintercept = bias, linetype = "solid", color = "blue") +
  geom_hline(yintercept = loa_upper, linetype = "dashed", color = "red") +
  geom_hline(yintercept = loa_lower, linetype = "dashed", color = "red") +
  scale_x_continuous(
    labels = sec_to_hhmm,
    name = "Mean of Tanda Prediction and Actual Time (hh:mm)"
  ) +
  scale_y_continuous(
    name = "Difference: Actual - Predicted (sec)"
  ) +
  labs(
    title = "Bland–Altman Plot: Tanda Prediction vs Actual Marathon Time"
  ) +
  theme_minimal()

BA_plot

```

```{r}
#| eval: false
#| include: false
# Run the linear model
model <- lm(P ~ Avg_Dist_week_K, data = tanda_data)

r_squared <- summary(model)$r.squared
r <- sqrt(r_squared)


# Calculate Standard Error of Estimate (SEE) in sec/km
predicted <- predict(model)
residuals <- tanda_data$P - predicted
SEE <- sqrt(mean(residuals^2))

R_AvgDist <- paste("R:", round(r, 3))
SEE_AvgDist <-paste("SEE (sec/km):", round(SEE, 2))

R_AvgDist
SEE_AvgDist

```

```{r}
#| eval: false
#| include: false
# Run the linear model
model <- lm(P ~ Pace, data = tanda_data)


r_squared <- summary(model)$r.squared
r <- sqrt(r_squared)

predicted <- predict(model)
residuals <- tanda_data$P - predicted
SEE <- sqrt(mean(residuals^2))

# Output results
R_Pace <- paste("R:", round(r, 3))
SEE_Pace <-paste("SEE (sec/km):", round(SEE, 2))

R_Pace
SEE_Pace
```
